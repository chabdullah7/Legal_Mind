{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##Install Required Libraries"
      ],
      "metadata": {
        "id": "Fj3kQWP-6BjH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rtHbf02N5_-H"
      },
      "outputs": [],
      "source": [
        "!pip install -q \\\n",
        "    transformers==4.40.0 \\\n",
        "    peft==0.10.0 \\\n",
        "    accelerate \\\n",
        "    datasets==2.19.1 \\\n",
        "    scikit-learn==1.4.2 \\\n",
        "    sentence-transformers \\\n",
        "    umap-learn \\\n",
        "    gcsfs \\\n",
        "    PyPDF2 \\\n",
        "    pymupdf \\\n",
        "    faiss-cpu \\\n",
        "    langchain \\\n",
        "    langchain-openai \\\n",
        "    gradio\n",
        "\n",
        "!pip install numpy==1.26.4 --force-reinstall --no-cache-dir"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Necessary Imports"
      ],
      "metadata": {
        "id": "lH9fQkDK6IqF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import re\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "#Visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "#Machine Learning / Transformers\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "\n",
        "import torch\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForSequenceClassification,\n",
        "    Trainer,\n",
        "    TrainingArguments,\n",
        "    DataCollatorWithPadding\n",
        ")\n",
        "\n",
        "#Datasets\n",
        "from datasets import Dataset\n",
        "from google.colab import files"
      ],
      "metadata": {
        "id": "nOzxFYGN6AWP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Upload and Load Dataset"
      ],
      "metadata": {
        "id": "DD8DSrKe6UnI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "uploaded = files.upload()\n",
        "filename = list(uploaded.keys())[0]\n",
        "\n",
        "with open(filename, \"r\", encoding=\"utf-8\") as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "_I_D6qIm6Aa-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Cleaning"
      ],
      "metadata": {
        "id": "en5DAgAg6XPB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_text(text):\n",
        "    text = str(text).lower()\n",
        "    text = re.sub(r\"[\\n\\r\\t]\", \" \", text)\n",
        "    text = re.sub(r\"[\\\"']\", \"\", text)\n",
        "    text = re.sub(r\"[^a-z0-9 ,.\\[\\]()/\\-:]\", \"\", text)\n",
        "    text = re.sub(r\"\\.{2,}\", \".\", text)\n",
        "    text = re.sub(r\"\\s+\", \" \", text)\n",
        "    text = re.sub(r\"[,/]+\", \",\", text)\n",
        "    text = re.sub(r\"(,\\s*,)+\", \",\", text)\n",
        "    text = re.sub(r\"(,\\s*$)|(^\\s*,)\", \"\", text)\n",
        "    text = re.sub(r\"\\b(p\\s*,\\s*p\\s*,\\s*c)\\b\", \"ppc\", text)\n",
        "    return text.strip()\n",
        "\n",
        "def format_case(row):\n",
        "    summary = clean_text(row[\"summary\"])\n",
        "    petitioner = clean_text(row[\"petitioner_argument\"])\n",
        "    respondent = clean_text(row[\"respondent_argument\"])\n",
        "    case_type = clean_text(row.get(\"case_type\", \"\"))\n",
        "    sections = clean_text(\", \".join(row.get(\"offence_sections\", [])))\n",
        "    return f\"[SUMMARY] {summary} [PETITIONER] {petitioner} [RESPONDENT] {respondent} [CASE TYPE] {case_type} [SECTIONS] {sections}\"\n"
      ],
      "metadata": {
        "id": "1zHLvnTL6AdO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Clean Verdicts & Label Encoding"
      ],
      "metadata": {
        "id": "EP3BKtCr6bWT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Clean verdicts\n",
        "df[\"verdict\"] = df[\"verdict\"].apply(clean_text)\n",
        "\n",
        "#Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "df[\"label\"] = label_encoder.fit_transform(df[\"verdict\"])\n",
        "label_mapping = dict(zip(label_encoder.transform(label_encoder.classes_), label_encoder.classes_))\n",
        "df[\"label_name\"] = df[\"label\"].map(label_mapping)\n",
        "\n",
        "#Filter labels with >= 10 samples\n",
        "label_counts = df[\"label\"].value_counts()\n",
        "valid_labels = label_counts[label_counts >= 10].index.tolist()\n",
        "df = df[df[\"label\"].isin(valid_labels)].reset_index(drop=True)\n"
      ],
      "metadata": {
        "id": "viPF-Hn06Afd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Visualize Label Distribution"
      ],
      "metadata": {
        "id": "nQOKHOff6fOy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12, 6))\n",
        "sns.countplot(data=df, x=\"label_name\", palette=\"Set3\", order=df[\"label_name\"].value_counts().index)\n",
        "plt.title(\"Filtered Verdict Distribution\")\n",
        "plt.xlabel(\"Verdict Label\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "rWzQ0-G66Ahx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Train/Test Split & Dataset Formatting"
      ],
      "metadata": {
        "id": "tObMXL_l6kfz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df, val_df = train_test_split(df, test_size=0.2, stratify=df[\"label\"], random_state=42)\n",
        "train_df[\"text\"] = train_df.apply(format_case, axis=1)\n",
        "val_df[\"text\"] = val_df.apply(format_case, axis=1)\n",
        "\n",
        "train_ds = Dataset.from_pandas(train_df[[\"text\", \"label\"]])\n",
        "val_ds = Dataset.from_pandas(val_df[[\"text\", \"label\"]])"
      ],
      "metadata": {
        "id": "zgYQp0ka6Aj9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Tokenization"
      ],
      "metadata": {
        "id": "eNRd-IJ26obM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"nlpaueb/legal-bert-base-uncased\")\n",
        "\n",
        "def tokenize(batch):\n",
        "    return tokenizer(batch[\"text\"], padding=\"max_length\", truncation=True, max_length=512)\n",
        "\n",
        "tokenized_train_ds = train_ds.map(tokenize, batched=True)\n",
        "tokenized_val_ds = val_ds.map(tokenize, batched=True)\n",
        "\n",
        "#Remove unnecessary columns\n",
        "cols_to_remove = [col for col in tokenized_train_ds.column_names if col.startswith(\"__\")]\n",
        "tokenized_train_ds = tokenized_train_ds.remove_columns(cols_to_remove)\n",
        "tokenized_val_ds = tokenized_val_ds.remove_columns(cols_to_remove)\n"
      ],
      "metadata": {
        "id": "OiuR0Y2x6AmV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Load Model"
      ],
      "metadata": {
        "id": "oLGDKDK16spN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_labels = df[\"label\"].max() + 1\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    \"nlpaueb/legal-bert-base-uncased\",\n",
        "    num_labels=num_labels\n",
        ")"
      ],
      "metadata": {
        "id": "U73fUqDE6Aol"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Training Setup & Metrics"
      ],
      "metadata": {
        "id": "viCva8206xY9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    num_train_epochs=30,\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    logging_strategy=\"epoch\",\n",
        "    logging_dir=\"./logs\",\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"accuracy\"\n",
        ")\n",
        "\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
        "\n",
        "def compute_metrics(pred):\n",
        "    labels = pred.label_ids\n",
        "    preds = np.argmax(pred.predictions, axis=1)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average=\"weighted\", zero_division=0)\n",
        "    acc = accuracy_score(labels, preds)\n",
        "    return {\"accuracy\": acc, \"precision\": precision, \"recall\": recall, \"f1\": f1}\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_train_ds,\n",
        "    eval_dataset=tokenized_val_ds,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics\n",
        ")\n"
      ],
      "metadata": {
        "id": "QIjI23Ww6Aq3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Train Model"
      ],
      "metadata": {
        "id": "OR8SospO62qZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "id": "Vbeku36v6AtV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Evaluation & Plotting"
      ],
      "metadata": {
        "id": "iCUHExPq67cX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Auto-detect latest checkpoint\n",
        "checkpoint_dirs = [ckpt for ckpt in os.listdir(\"./results\") if ckpt.startswith(\"checkpoint\")]\n",
        "latest_ckpt = sorted(checkpoint_dirs, key=lambda x: int(x.split(\"-\")[-1]))[-1]\n",
        "trainer_state_path = f\"./results/{latest_ckpt}/trainer_state.json\"\n",
        "\n",
        "with open(trainer_state_path, \"r\") as f:\n",
        "    logs = json.load(f)\n",
        "\n",
        "log_history = logs[\"log_history\"]\n",
        "epochs, eval_loss, eval_accuracy, eval_precision, eval_recall, eval_f1 = [], [], [], [], [], []\n",
        "\n",
        "for entry in log_history:\n",
        "    if \"eval_loss\" in entry:\n",
        "        epochs.append(entry[\"epoch\"])\n",
        "        eval_loss.append(entry.get(\"eval_loss\"))\n",
        "        eval_accuracy.append(entry.get(\"eval_accuracy\"))\n",
        "        eval_precision.append(entry.get(\"eval_precision\"))\n",
        "        eval_recall.append(entry.get(\"eval_recall\"))\n",
        "        eval_f1.append(entry.get(\"eval_f1\"))\n",
        "\n",
        "#Plot\n",
        "plt.figure(figsize=(14, 7))\n",
        "plt.plot(epochs, eval_loss, label=\"Eval Loss\", marker='o', color='crimson')\n",
        "plt.plot(epochs, eval_accuracy, label=\"Accuracy\", marker='s', color='blue')\n",
        "plt.plot(epochs, eval_precision, label=\"Precision\", marker='^', color='green')\n",
        "plt.plot(epochs, eval_recall, label=\"Recall\", marker='v', color='darkorange')\n",
        "plt.plot(epochs, eval_f1, label=\"F1 Score\", marker='D', color='purple')\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Metric Value\")\n",
        "plt.title(\"Evaluation Metrics Over Epochs\")\n",
        "plt.ylim(0, 1.05)\n",
        "plt.grid(True, linestyle='--', alpha=0.6)\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "mlF3oYlF6Av1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Save Model"
      ],
      "metadata": {
        "id": "DadOAIvB6_hf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.save_model(\"./best_model\")\n",
        "tokenizer.save_pretrained(\"./best_model\")"
      ],
      "metadata": {
        "id": "8NID2vZo6AyN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Inference / Prediction Function"
      ],
      "metadata": {
        "id": "P_1LIc2d7Ita"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Load best saved model and tokenizer\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "import torch\n",
        "\n",
        "#Load from saved directory\n",
        "model_path = \"./best_model\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
        "\n",
        "#Move model to correct device (GPU if available)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "#Prediction Function\n",
        "def predict_verdict(case, model, tokenizer, label_mapping):\n",
        "    formatted_text = format_case(case)\n",
        "\n",
        "    #Prepare inputs and move to device\n",
        "    inputs = tokenizer(\n",
        "        formatted_text,\n",
        "        return_tensors=\"pt\",\n",
        "        truncation=True,\n",
        "        padding=True,\n",
        "        max_length=512\n",
        "    ).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "        predicted_label = torch.argmax(outputs.logits, dim=1).item()\n",
        "\n",
        "    return label_mapping[predicted_label]\n",
        "\n",
        "#Example Test Case\n",
        "sample_case = {\n",
        "    \"summary\": \"The appellant was convicted under Section 302 for murder but argued that the evidence was circumstantial.\",\n",
        "    \"petitioner_argument\": \"The petitioner argued there was no direct witness and the case relied on weak circumstantial evidence.\",\n",
        "    \"respondent_argument\": \"The prosecution maintained that the motive and weapon recovery strongly supported conviction.\",\n",
        "    \"case_type\": \"Criminal Appeal\",\n",
        "    \"offence_sections\": [\"302\", \"34\"]\n",
        "}\n",
        "\n",
        "#Predict verdict\n",
        "predicted_verdict = predict_verdict(sample_case, model, tokenizer, label_mapping)\n",
        "print(\"Predicted Verdict:\", predicted_verdict)\n"
      ],
      "metadata": {
        "id": "1XbiriaS6A01"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Download Model"
      ],
      "metadata": {
        "id": "_OZvopXo7MrS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r best_model.zip best_model\n",
        "\n",
        "from google.colab import files\n",
        "files.download(\"best_model.zip\")\n"
      ],
      "metadata": {
        "id": "dmZGSdYg6A3X"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}